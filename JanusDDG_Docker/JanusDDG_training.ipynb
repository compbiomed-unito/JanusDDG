{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0d193-11f5-4e42-b76f-99c49e887da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from torch_geometric.utils import to_networkx\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Dataset\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import random\n",
    "from sklearn.metrics import root_mean_squared_error,mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522ad10-397a-4b36-abe8-3c215b897876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # Numpy random\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch GPU \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53fc53-6a66-4f06-aa44-c6e5ac8c52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "class DeltaDataset(Dataset):\n",
    "    def __init__(self, data, dim_embedding, inv = False):\n",
    "        self.data = data\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.inv = inv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.inv: \n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['mut_type'], dtype=torch.float32),    \n",
    "                'mut_type': torch.tensor(sample['wild_type'], dtype=torch.float32),                \n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                'ddg': torch.tensor(-float(sample['ddg']), dtype=torch.float32),       \n",
    "                'pos_mut': torch.tensor(sample['pos_mut'], dtype=torch.int64),\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['wild_type'], dtype=torch.float32),\n",
    "                'mut_type': torch.tensor(sample['mut_type'],dtype=torch.float32),\n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                'ddg': torch.tensor(float(sample['ddg']), dtype=torch.float32),\n",
    "                'pos_mut': torch.tensor(sample['pos_mut'], dtype=torch.int64),\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37194b0e-d9a3-4928-aa15-b510cbe7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(sample['wild_type'].shape[0] for sample in batch)  # Max sequence length in batch   700\n",
    "    max_features = max(sample['wild_type'].shape[1] for sample in batch)  # Max feature size\n",
    "\n",
    "    padded_batch = {\n",
    "        'id': [],\n",
    "        'wild_type': [],\n",
    "        'mut_type': [],\n",
    "        'length': [],\n",
    "        'ddg': [],\n",
    "        'pos_mut': [],\n",
    "    }\n",
    "\n",
    "    for sample in batch:\n",
    "        wild_type_padded = F.pad(sample['wild_type'], (0, max_features - sample['wild_type'].shape[1], \n",
    "                                                       0, max_len - sample['wild_type'].shape[0]))\n",
    "        mut_type_padded = F.pad(sample['mut_type'], (0, max_features - sample['mut_type'].shape[1], \n",
    "                                                     0, max_len - sample['mut_type'].shape[0]))\n",
    "    \n",
    "\n",
    "        padded_batch['id'].append(sample['id'])  \n",
    "        padded_batch['wild_type'].append(wild_type_padded)  \n",
    "        padded_batch['mut_type'].append(mut_type_padded)  \n",
    "        padded_batch['length'].append(sample['length'])#append(torch.tensor(sample['length'], dtype=torch.float32))  \n",
    "        padded_batch['ddg'].append(sample['ddg'])#append(torch.tensor(float(sample['ddg']), dtype=torch.float32))\n",
    "\n",
    "    # Convert list of tensors into a single batch tensor\n",
    "    padded_batch['wild_type'] = torch.stack(padded_batch['wild_type'])  # Shape: (batch_size, max_len, max_features)\n",
    "    padded_batch['mut_type'] = torch.stack(padded_batch['mut_type'])  \n",
    "    padded_batch['length'] = torch.stack(padded_batch['length'])  \n",
    "    padded_batch['ddg'] = torch.stack(padded_batch['ddg'])\n",
    "\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "\n",
    "def dataloader_generation(E_TYPE, train_path, validation_path, test_path, batch_size = 128, dataloader_shuffle = True, inv= False,sample_weights=None):\n",
    "    \n",
    "    EMBEDDING_TYPE = E_TYPE\n",
    "    \n",
    "    if EMBEDDING_TYPE == 'ESM2':\n",
    "\n",
    "        '''train formato da s2648 + UnionV e DA; 1000 dei DA sono usati nel validation insieme a s669 DA\n",
    "        '''\n",
    "        \n",
    "        dim_embedding = 1280\n",
    "        \n",
    "        dataset_train = []\n",
    "        dataset_validation = []\n",
    "        dataset_test = []\n",
    "\n",
    "        \n",
    "        for path in train_path:\n",
    "            with open(path, 'rb') as f:\n",
    "                dataset_train += pickle.load(f)\n",
    "        \n",
    "        for path in validation_path:\n",
    "            with open(path, 'rb') as f:\n",
    "                dataset_validation += pickle.load(f)\n",
    "        \n",
    "        for path in test_path:           \n",
    "            with open(path, 'rb') as f:\n",
    "                dataset_test += pickle.load(f)\n",
    "    \n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "    dataset_train = DeltaDataset(dataset_train, dim_embedding, inv = inv)  \n",
    "    dataset_test = DeltaDataset(dataset_test, dim_embedding, inv = inv)\n",
    "    dataset_validation = DeltaDataset(dataset_validation, dim_embedding, inv = inv)\n",
    "    \n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=dataloader_shuffle, collate_fn=collate_fn)#, sampler=sampler)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=dataloader_shuffle, collate_fn=collate_fn)\n",
    "    dataloader_validation = DataLoader(dataset_validation, batch_size=batch_size, shuffle=dataloader_shuffle, collate_fn=collate_fn)\n",
    "\n",
    "    return dataloader_train, dataloader_validation, dataloader_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b306576-bd45-49d6-88f3-c90a2a6a97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "import random\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "E_TYPE='ESM2'\n",
    "folds = [0,1,2,3,4]\n",
    "Model_num = 0\n",
    "val_set = [folds[Model_num]]  \n",
    "train_set = list(chain(folds[:Model_num], folds[Model_num+1:]))\n",
    "\n",
    "train_path = [f'train_data/s2450_fold_{i}.pkl' for i in [0,1,2,3,4]]+[f'train_data/s2450_fold_{i}_inv.pkl' for i in [0,1,2,3,4]]\n",
    "val_path = [f'train_data/s2450_fold_{i}.pkl' for i in [0,1,2,3,4]]+[f'train_data/s2450_fold_{i}_inv.pkl' for i in [0,1,2,3,4]]\n",
    "test_path = ['train_data/s669_Castrense.pkl']\n",
    "\n",
    "dataloader_train, dataloader_validation, dataloader_test = dataloader_generation(E_TYPE, train_path = train_path, validation_path = val_path,\n",
    "                                                                                 test_path = test_path, batch_size = 6,\n",
    "                                                                                 dataloader_shuffle = True, inv= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d0d54-2d6e-478e-b273-f7d4b7d2c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE EMBEDDINGS\n",
    "data_iter = iter(dataloader_train)\n",
    "# Ottieni il primo batch\n",
    "batch = next(data_iter)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot((batch['wild_type'][0,:,:].sum(dim=1) - batch['mut_type'][0,:,:].sum(dim=1))[:int(batch['length'][0])],label='delta')\n",
    "sns.lineplot(batch['wild_type'][0,:,:].sum(dim=1)[:int(batch['length'][0])],label='WT')\n",
    "plt.legend()\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Embedding Value (Sum)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b46a1f-ded3-4ab0-bbcb-d91ab2483241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def output_model_from_batch(batch, model, device, train=True):\n",
    "\n",
    "    '''Dato un modello pytorch e batch restituisce: output_modello, True labels'''\n",
    "    \n",
    "    x_wild = batch['wild_type'].float().to(device)\n",
    "    x_mut = batch['mut_type'].float().to(device)\n",
    "    labels = batch['ddg'].float().to(device)\n",
    "    length = batch['length'].to(device)   \n",
    "        \n",
    "    output_ddg = model(x_wild, x_mut, length, train = train)\n",
    "    \n",
    "    return output_ddg, labels\n",
    "\n",
    "\n",
    "def training_and_validation_loop_ddg(model, dataloader_train, dataloader_test, dataloader_validation, path_save_fig, epochs=20, lr =0.001, patience=10):\n",
    "            \n",
    "    criterion =nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    pearson_r_train = []\n",
    "    pearson_r_test = []\n",
    "    pearson_r_validation = []\n",
    "    \n",
    "    loss_ddg_train = []\n",
    "    loss_ddg_test = []\n",
    "    loss_ddg_validation = []\n",
    "\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs):\n",
    "            \n",
    "        # Training Loop\n",
    "        model.train()\n",
    "        preds_ddg_train = []\n",
    "        preds_dgw_train = []\n",
    "        preds_dgm_train = []\n",
    "        preds_coerenza_train = []\n",
    "\n",
    "        labels_tot_epoch = []\n",
    "\n",
    "        for i, batch in enumerate(dataloader_train):\n",
    "            train = True\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output_ddg, labels = output_model_from_batch(batch, model, device, train=train)            \n",
    "            \n",
    "            if isinstance(output_ddg, list):\n",
    "                # Compute the loss for each output and sum them\n",
    "                loss_list = [criterion(output_aa, labels) for output_aa in output_ddg]\n",
    "                loss_ddg = torch.stack(loss_list).sum()\n",
    "                output_ddg  = torch.mean(torch.stack(output_ddg), dim=0)\n",
    "            else: \n",
    "                loss_ddg = criterion(output_ddg, labels) \n",
    "            \n",
    "            tot_loss = loss_ddg \n",
    "            \n",
    "            # Backpropagation and optimization\n",
    "            tot_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Collect predictions\n",
    "            preds_ddg_train.extend(output_ddg.cpu().reshape(-1).tolist())\n",
    "            labels_tot_epoch.extend(labels.cpu().tolist())\n",
    "\n",
    "        # Calculate and print train metrics\n",
    "        train_loss = mean_squared_error(preds_ddg_train, labels_tot_epoch)\n",
    "        train_correlation = pearsonr(preds_ddg_train, labels_tot_epoch)[0]\n",
    "        train_spearman = spearmanr(preds_ddg_train, labels_tot_epoch)[0]\n",
    "        \n",
    "        loss_ddg_train.append(train_loss)\n",
    "        pearson_r_train.append(train_correlation)\n",
    "        \n",
    "        # Validation Loop\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "                \n",
    "        all_preds_validation = []\n",
    "        all_labels_validation = []\n",
    "        all_preds_test = []\n",
    "        all_labels_test = []\n",
    "      \n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            train = False\n",
    "            for i, batch in enumerate(dataloader_test):\n",
    "\n",
    "                output_ddg,labels = output_model_from_batch(batch, model, device, train=train) \n",
    "                    \n",
    "                all_preds_test.extend(output_ddg.cpu().reshape(-1).tolist())\n",
    "                all_labels_test.extend(labels.cpu().tolist())\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            test_loss = mean_squared_error(all_preds_test, all_labels_test)\n",
    "            loss_ddg_test.append(test_loss)\n",
    "            \n",
    "            test_correlation, _ = pearsonr(all_preds_test, all_labels_test)\n",
    "            pearson_r_test.append(test_correlation)\n",
    "\n",
    "            for i, batch in enumerate(dataloader_validation):\n",
    "                output_ddg,labels = output_model_from_batch(batch, model, device, train=train)\n",
    "\n",
    "                all_preds_validation.extend(output_ddg.cpu().reshape(-1).tolist())\n",
    "                all_labels_validation.extend([x for x in labels.cpu().tolist()])\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            val_loss = mean_squared_error(all_preds_validation, all_labels_validation)\n",
    "            loss_ddg_validation.append(val_loss)\n",
    "            \n",
    "            val_correlation, _ = pearsonr(all_preds_validation, all_labels_validation)\n",
    "            pearson_r_validation.append(val_correlation)\n",
    "\n",
    "        \n",
    "        if val_correlation >= max(pearson_r_validation): \n",
    "            best_model = copy.deepcopy(model)\n",
    "            print(f'\\033[91mEpoch {epoch+1}/{num_epochs}')\n",
    "            print(f'Train -      Loss: {train_loss:.4f}, Pearson r: {train_correlation:.4f}, Rho spearman: {train_spearman:.4f}')\n",
    "            print(f'Validation - Loss: {val_loss:.4f}, Pearson r: {val_correlation:.4f}, Rho spearman: {spearmanr(all_preds_validation, all_labels_validation)[0]:.4f}',)        \n",
    "            print(f'Test -       Loss: {test_loss:.4f}, Pearson r: {test_correlation:.4f}, Rho spearman: {spearmanr(all_preds_test, all_labels_test)[0]:.4f}\\033[0m\\n')\n",
    "      \n",
    "\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print(f'Train -      Loss: {train_loss:.4f}, Pearson r: {train_correlation:.4f}, Rho spearman: {train_spearman:.4f}')\n",
    "            print(f'Validation - Loss: {val_loss:.4f}, Pearson r: {val_correlation:.4f}, Rho spearman: {spearmanr(all_preds_validation, all_labels_validation)[0]:.4f}',)        \n",
    "            print(f'Test -       Loss: {test_loss:.4f}, Pearson r: {test_correlation:.4f}, Rho spearman: {spearmanr(all_preds_test, all_labels_test)[0]:.4f}\\n')\n",
    "                  \n",
    "        if epoch > (np.argmax(pearson_r_validation) + patience):\n",
    "            print(f'\\033[91mEarly stopping at epoch {epoch+1}\\033[0m')\n",
    "            break\n",
    "    \n",
    "    pearson_max_val = np.max(pearson_r_validation)\n",
    "\n",
    "    return pearson_r_train, pearson_r_validation, pearson_r_test, loss_ddg_train, loss_ddg_validation, loss_ddg_test, pearson_max_val, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f7e6d-973d-4fb4-bf11-e89af78108e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Attention_DDG(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_module, cross_att=False, dual_cross_att= False,**transf_parameters):\n",
    "        super().__init__()\n",
    "        self.base_ddg = base_module(**transf_parameters, cross_att=cross_att, dual_cross_att= dual_cross_att).to(device)\n",
    "    \n",
    "    def forward(self, x_wild, x_mut,length, hydra_slim=None, train = True):\n",
    "\n",
    "        delta_x_dir = x_wild - x_mut\n",
    "        output_TCA_dir = self.base_ddg(delta_x_dir, x_wild, length)\n",
    "\n",
    "        return output_TCA_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98febd2-26c0-4c75-9768-9a9871b263e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def apply_masked_pooling(position_attn_output, padding_mask):\n",
    "\n",
    "    # Convert mask to float for element-wise multiplication\n",
    "    padding_mask = padding_mask.float()\n",
    "\n",
    "    # Global Average Pooling (GAP) - Exclude padded tokens\n",
    "    # Sum only over valid positions (padding_mask is False for valid positions)\n",
    "    sum_output = torch.sum(position_attn_output * (1 - padding_mask.unsqueeze(-1)), dim=1)  # (batch_size, feature_dim)\n",
    "    valid_count = torch.sum((1 - padding_mask).float(), dim=1)  # (batch_size,)\n",
    "    gap = sum_output / valid_count.unsqueeze(-1)  # Divide by number of valid positions\n",
    "\n",
    "    # Global Max Pooling (GMP) - Exclude padded tokens\n",
    "    # Set padded positions to -inf so they don't affect the max computation\n",
    "    position_attn_output_masked = position_attn_output * (1 - padding_mask.unsqueeze(-1)) + (padding_mask.unsqueeze(-1) * (- 1e10))\n",
    "    gmp, _ = torch.max(position_attn_output_masked, dim=1)  # (batch_size, feature_dim)\n",
    "\n",
    "    return gap, gmp\n",
    "\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=3700):\n",
    "        super(SinusoidalPositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape (1, max_len, embedding_dim)\n",
    "        self.register_buffer('pe', pe)  # Salvato come tensore fisso (non parametro)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_heads=8, dropout_rate=0., num_experts=1, f_activation = nn.ReLU(), kernel_size=20, cross_att = True,\n",
    "                dual_cross_att=True):\n",
    "        \n",
    "        super(TransformerRegression, self).__init__()\n",
    "\n",
    "        self.embedding_dim = input_dim\n",
    "        self.act = f_activation\n",
    "        self.max_len = 3700 #MAX PROTEIN LEN\n",
    "        out_channels = 128 \n",
    "        kernel_size = 20\n",
    "        padding = 0\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding) \n",
    "        \n",
    "        self.conv1d_wild = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(out_channels)\n",
    "        self.norm2 = nn.LayerNorm(out_channels)\n",
    "        \n",
    "        # Cross-attention layers\n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(out_channels, 3700)\n",
    "        self.speach_att_type = True\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first=True )\n",
    "        self.inverse_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first =True)\n",
    "        \n",
    "        dim_position_wise_FFN = out_channels*2\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_position_wise_FFN)\n",
    "        self.router = nn.Linear(dim_position_wise_FFN, num_experts) \n",
    "\n",
    "        self.pw_ffnn = nn.Sequential(\n",
    "            nn.Linear(dim_position_wise_FFN, 512),\n",
    "            self.act,\n",
    "            nn.Linear(512, dim_position_wise_FFN)\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.Linear_ddg = nn.Linear(dim_position_wise_FFN*2, 1)\n",
    "\n",
    "            \n",
    "\n",
    "    def create_padding_mask(self, length, seq_len, batch_size):\n",
    "        \"\"\"\n",
    "        Create a padding mask for multihead attention.\n",
    "        length: Tensor of shape (batch_size,) containing the actual lengths of the sequences.\n",
    "        seq_len: The maximum sequence length.\n",
    "        batch_size: The number of sequences in the batch.\n",
    "        \n",
    "        Returns a padding mask of shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        mask = torch.arange(seq_len, device=length.device).unsqueeze(0) >= length.unsqueeze(1)\n",
    "        return mask\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, delta_w_m, x_wild, length):\n",
    "            \n",
    "            delta_w_m = delta_w_m.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_delta_w_m = self.conv1d(delta_w_m)\n",
    "            C_delta_w_m = C_delta_w_m.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_delta_w_m = self.positional_encoding(C_delta_w_m)\n",
    "            \n",
    "            x_wild = x_wild.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_x_wild = self.conv1d_wild(x_wild)\n",
    "            C_x_wild = C_x_wild.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_x_wild = self.positional_encoding(C_x_wild)            \n",
    "            \n",
    "            batch_size, seq_len, feature_dim = C_x_wild.size()\n",
    "\n",
    "            padding_mask = self.create_padding_mask(length, seq_len, batch_size)        \n",
    "                    \n",
    "            if self.speach_att_type:\n",
    "                print('ATTENTION TYPE: Dual cross Attention\\n q = wild , k = delta, v = delta and q = delta , k = wild, v = wild \\n ----------------------------------')\n",
    "                self.speach_att_type = False\n",
    "                \n",
    "            direct_attn_output, _ = self.multihead_attention(C_x_wild, C_delta_w_m, C_delta_w_m, key_padding_mask=padding_mask)\n",
    "            direct_attn_output += C_delta_w_m \n",
    "            direct_attn_output = self.norm1(direct_attn_output)                        \n",
    "            \n",
    "            inverse_attn_output, _ = self.inverse_attention(C_delta_w_m, C_x_wild, C_x_wild, key_padding_mask=padding_mask)                   \n",
    "            inverse_attn_output += C_x_wild  \n",
    "            inverse_attn_output = self.norm2(inverse_attn_output)\n",
    "            \n",
    "            attn_output = torch.cat([direct_attn_output, inverse_attn_output], dim=-1)\n",
    "\n",
    "            output = self.pw_ffnn(attn_output)\n",
    "    \n",
    "            position_attn_output = attn_output + output\n",
    "    \n",
    "            position_attn_output = self.norm3(position_attn_output)\n",
    "    \n",
    "            gap, gmp = apply_masked_pooling(position_attn_output, padding_mask)\n",
    "    \n",
    "            # Concatenate GAP and GMP\n",
    "            pooled_output = torch.cat([gap, gmp], dim=-1)  # (batch_size, 2 * feature_dim)\n",
    "    \n",
    "            # Pass through FFNN to predict DDG\n",
    "            x = self.Linear_ddg(pooled_output)        \n",
    "            \n",
    "            return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245621e5-bf63-4d4f-a923-f1bac00c67ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PROVA base base\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lr = 1e-4\n",
    "input_dim = 1280\n",
    "\n",
    "transf_parameters={'input_dim':1280, 'num_heads':8,\n",
    "                    'dropout_rate':0.,}\n",
    "\n",
    "patience = 300\n",
    "DDG_model = TransformerRegression\n",
    "Final_model = Cross_Attention_DDG(DDG_model, cross_att = True, dual_cross_att=True, **transf_parameters)\n",
    "\n",
    "path_save_fig = 'JanusDDG \\n ----------------------------------'\n",
    "print(path_save_fig)\n",
    "p_tr,p_val, p_te, l_tr,l_val, l_te, pearson_max_val, best_model = training_and_validation_loop_ddg(Final_model, dataloader_train, dataloader_test,\n",
    "                                                                                   dataloader_validation,\n",
    "                                                                                   path_save_fig, epochs=300, lr =lr,patience = patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa01826-76f9-4c6f-9eb7-175e59270e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(Final_model, 'JanusDDG.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
