{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0d193-11f5-4e42-b76f-99c49e887da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from torch_geometric.utils import to_networkx\n",
    "import os\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Dataset\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import random\n",
    "from sklearn.metrics import root_mean_squared_error,mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522ad10-397a-4b36-abe8-3c215b897876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # Numpy random\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (un singolo dispositivo)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch GPU (tutti i dispositivi, se usi multi-GPU)\n",
    "    torch.backends.cudnn.deterministic = True  # Comportamento deterministico di cuDNN\n",
    "    torch.backends.cudnn.benchmark = False  # Evita che cuDNN ottimizzi dinamicamente (influisce su riproducibilitÃ )\n",
    "\n",
    "# Imposta il seed\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5244a-fe04-49c4-8766-18daa9de6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm\n",
    "\n",
    "model_esm, alphabet_esm = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_esm = model_esm.to(device)\n",
    "batch_converter_esm = alphabet_esm.get_batch_converter()\n",
    "model_esm.eval()\n",
    "\n",
    "def Esm2_embedding(seq, model_esm = model_esm, batch_converter_esm = batch_converter_esm):\n",
    "    sequences = [(\"protein\", seq),]\n",
    "    \n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter_esm(sequences)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model_esm(batch_tokens, repr_layers=[33])  # Usa l'ultimo layer\n",
    "        token_representations = results[\"representations\"][33]\n",
    "    \n",
    "    embedding = token_representations[0, 1:-1].cpu().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53fc53-6a66-4f06-aa44-c6e5ac8c52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "class DeltaDataset(Dataset):\n",
    "    def __init__(self, data, dim_embedding, inv = False):\n",
    "        self.data = data\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.inv = inv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.inv: \n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['mut_type'], dtype=torch.float32),    # inverto mut con wild \n",
    "                'mut_type': torch.tensor(sample['wild_type'], dtype=torch.float32),    # inverto mut con wild             \n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                'ddg': torch.tensor(-float(sample['ddg']), dtype=torch.float32),       # -ddg\n",
    "                'pos_mut': torch.tensor(sample['pos_mut'], dtype=torch.int64),\n",
    "                'hydra_slim': torch.tensor(sample['mut_type']*0, dtype=torch.float32),\n",
    "\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['wild_type'], dtype=torch.float32),\n",
    "                'mut_type': torch.tensor(sample['mut_type'],dtype=torch.float32),\n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                'ddg': torch.tensor(float(sample['ddg']), dtype=torch.float32),\n",
    "                'pos_mut': torch.tensor(sample['pos_mut'], dtype=torch.int64),\n",
    "                'hydra_slim': torch.tensor(sample['mut_type']*0, dtype=torch.float32),\n",
    "\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37194b0e-d9a3-4928-aa15-b510cbe7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(sample['wild_type'].shape[0] for sample in batch)  # Max sequence length in batch   700\n",
    "    max_features = max(sample['wild_type'].shape[1] for sample in batch)  # Max feature size\n",
    "\n",
    "    padded_batch = {\n",
    "        'id': [],\n",
    "        'wild_type': [],\n",
    "        'mut_type': [],\n",
    "        'length': [],\n",
    "        'ddg': [],\n",
    "        'pos_mut': [],\n",
    "        'hydra_slim':[],\n",
    "    }\n",
    "\n",
    "    for sample in batch:\n",
    "        \n",
    "        wild_type_padded = F.pad(sample['wild_type'], (0, max_features - sample['wild_type'].shape[1], \n",
    "                                                       0, max_len - sample['wild_type'].shape[0]))\n",
    "        \n",
    "        mut_type_padded = F.pad(sample['mut_type'], (0, max_features - sample['mut_type'].shape[1], \n",
    "                                                     0, max_len - sample['mut_type'].shape[0]))\n",
    "        \n",
    "        hydra_slim_type_padded = F.pad(sample['hydra_slim'], (0, max_features - sample['hydra_slim'].shape[1], \n",
    "                                                       0, max_len - sample['hydra_slim'].shape[0]))        \n",
    "\n",
    "        padded_batch['id'].append(sample['id'])  \n",
    "        padded_batch['wild_type'].append(wild_type_padded)  \n",
    "        padded_batch['mut_type'].append(mut_type_padded)  \n",
    "        padded_batch['length'].append(sample['length'])\n",
    "        padded_batch['ddg'].append(sample['ddg'])\n",
    "        padded_batch['hydra_slim'].append(hydra_slim_type_padded)\n",
    "\n",
    "\n",
    "    # Convert list of tensors into a single batch tensor\n",
    "    padded_batch['wild_type'] = torch.stack(padded_batch['wild_type'])  # Shape: (batch_size, max_len, max_features)\n",
    "    padded_batch['mut_type'] = torch.stack(padded_batch['mut_type'])  \n",
    "    padded_batch['length'] = torch.stack(padded_batch['length'])  \n",
    "    padded_batch['ddg'] = torch.stack(padded_batch['ddg'])\n",
    "    padded_batch['hydra_slim'] = torch.stack(padded_batch['hydra_slim'])\n",
    "\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "def dataloader_generation(path, collate_fn, batch_size = 128, dataloader_shuffle = True, inv= False):\n",
    "    \n",
    "    dim_embedding = 1280\n",
    "    dataset= []\n",
    "\n",
    "    for path in path:\n",
    "        with open(path, 'rb') as f:\n",
    "            dataset += pickle.load(f)\n",
    "\n",
    "    delta_dataset = DeltaDataset(dataset, dim_embedding, inv = inv)  \n",
    "    dataloader_delta = DataLoader(delta_dataset, batch_size=batch_size, shuffle=dataloader_shuffle, collate_fn=collate_fn)\n",
    "\n",
    "    return dataloader_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b306576-bd45-49d6-88f3-c90a2a6a97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader  # Use standard PyTorch DataLoader\n",
    "import random\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "train_path =[f'train_data/s2450_fold_{i}_hydra_slim.pkl' for i in [0,1,2,3,4]]+[f'train_data/s2450_fold_{i}_hydra_slim_inv.pkl' for i in [0,1,2,3,4]]#+[f's2450_fold_{i}_hydra_slim.pkl' for i in [0,1,2,3,4]]+[f's2450_fold_{i}_hydra_slim_inv.pkl' for i in [0,1,2,3,4]]\n",
    "\n",
    "val_path = ['train_data/M28_test.pkl']\n",
    "test_path = ['train_data/M28_test.pkl']\n",
    "\n",
    "dataloader_train = dataloader_generation(path = train_path, batch_size = 6,collate_fn=collate_fn, dataloader_shuffle = True, inv= False)\n",
    "dataloader_validation = dataloader_generation(path = val_path, batch_size = 1, collate_fn=collate_fn, dataloader_shuffle = False, inv= False)\n",
    "dataloader_test = dataloader_generation(path = test_path, batch_size = 1, collate_fn=collate_fn, dataloader_shuffle = False, inv= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b46a1f-ded3-4ab0-bbcb-d91ab2483241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def output_model_from_batch(batch, model, device, hydra = False,train=False):\n",
    "    \n",
    "    x_wild = batch['wild_type'].float().to(device)\n",
    "    x_mut = batch['mut_type'].float().to(device)\n",
    "    hydra_slim = batch['hydra_slim'].float().to(device)\n",
    "    labels = batch['ddg'].float().to(device)\n",
    "    length = batch['length'].to(device)\n",
    "    output_ddg = model(x_wild, x_mut, hydra_slim, length, hydra=hydra, train = train)\n",
    "    \n",
    "    return output_ddg, labels\n",
    "\n",
    "\n",
    "\n",
    "def training_and_validation_loop_ddg(model, dataloader_train, dataloader_test, dataloader_validation, path_save_fig, epochs=20, lr =0.001, patience=10):\n",
    "            \n",
    "    criterion =nn.MSELoss()# nn.HuberLoss()#nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    pearson_r_train = []\n",
    "    pearson_r_test = []\n",
    "    pearson_r_validation = []\n",
    "    \n",
    "    loss_ddg_train = []\n",
    "    loss_ddg_train_TRANS = []\n",
    "    loss_ddg_train_TOT = []\n",
    "    \n",
    "    loss_ddg_validation = []\n",
    "    loss_ddg_validation_TRANS = []\n",
    "    loss_ddg_validation_TOT = []\n",
    "    \n",
    "    loss_ddg_test = []\n",
    "    loss_ddg_test_TRANS=[]\n",
    "    loss_ddg_test_TOT = []\n",
    "\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs):\n",
    "            \n",
    "        # Training Loop\n",
    "        model.train()\n",
    "        preds_ddg_train = []\n",
    "        labels_tot_epoch = []\n",
    "\n",
    "        preds_ddg_train_TRANS = []\n",
    "        labels_tot_epoch_TRANS = []\n",
    "\n",
    "        for i, batch in enumerate(dataloader_train):\n",
    "            train = True\n",
    "            optimizer.zero_grad()\n",
    "            output_ddg_train, labels_train = output_model_from_batch(batch, model, device, hydra=False, train=True)\n",
    "            output_ddg_HYDRA_SLIM_train, _ = output_model_from_batch(batch, model, device, hydra=True, train=True)\n",
    "            \n",
    "            loss_ddg = criterion(output_ddg_train, labels_train)  #usa se NON uso hydra            \n",
    "            tot_loss = loss_ddg + criterion(output_ddg_HYDRA_SLIM_train, output_ddg_train)\n",
    "            \n",
    "            # Backpropagation and optimization\n",
    "            tot_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Collect predictions\n",
    "            preds_ddg_train.extend(output_ddg_train.cpu().reshape(-1).tolist())\n",
    "            labels_tot_epoch.extend(labels_train.cpu().tolist())\n",
    "\n",
    "            preds_ddg_train_TRANS.extend(output_ddg_HYDRA_SLIM_train.cpu().reshape(-1).tolist())\n",
    "            labels_tot_epoch_TRANS.extend(output_ddg_train.cpu().tolist())            \n",
    "\n",
    "        # Calculate and print train metrics\n",
    "        train_loss = mean_squared_error(preds_ddg_train, labels_tot_epoch)\n",
    "        train_loss_TRANS = mean_squared_error(preds_ddg_train_TRANS, labels_tot_epoch_TRANS)\n",
    "        \n",
    "        train_correlation = pearsonr(preds_ddg_train, labels_tot_epoch)[0]\n",
    "        train_spearman = spearmanr(preds_ddg_train, labels_tot_epoch)[0]\n",
    "        \n",
    "        loss_ddg_train.append(train_loss)\n",
    "        loss_ddg_train_TRANS.append(train_loss_TRANS)\n",
    "        loss_ddg_train_TOT.append(train_loss_TRANS+train_loss)\n",
    "        pearson_r_train.append(train_correlation)\n",
    "        \n",
    "        # Validation Loop\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "                \n",
    "        all_preds_validation = []\n",
    "        all_labels_validation = []\n",
    "        all_preds_validation_TRANS = []\n",
    "\n",
    "        \n",
    "        all_preds_test = []\n",
    "        all_labels_test = []\n",
    "        all_preds_test_TRANS = []\n",
    "                \n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            for i, batch in enumerate(dataloader_test):\n",
    "\n",
    "                output_ddg_test, labels_test = output_model_from_batch(batch, model, device, hydra=False, train=False) \n",
    "                output_ddg_HYDRA_SLIM_test, _ = output_model_from_batch(batch, model, device, hydra=True, train=False)      \n",
    "                    \n",
    "                all_preds_test.extend(output_ddg_test.cpu().reshape(-1).tolist())\n",
    "                all_labels_test.extend(labels_test.cpu().tolist())\n",
    "\n",
    "                all_preds_test_TRANS.extend(output_ddg_HYDRA_SLIM_test.cpu().reshape(-1).tolist())\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            test_loss = mean_squared_error(all_preds_test, all_labels_test)\n",
    "            loss_ddg_test.append(test_loss)\n",
    "\n",
    "            test_loss_TRANS = mean_squared_error(all_preds_test_TRANS, all_preds_test)\n",
    "            loss_ddg_test_TRANS.append(test_loss_TRANS)\n",
    "\n",
    "            loss_ddg_test_TOT.append(test_loss+test_loss_TRANS)\n",
    "            \n",
    "            test_correlation, _ = pearsonr(all_preds_test, all_labels_test)\n",
    "            pearson_r_test.append(test_correlation)\n",
    "\n",
    "            test_correlation_TRANS = pearsonr(all_preds_test_TRANS, all_preds_test)\n",
    "\n",
    "            for i, batch in enumerate(dataloader_validation):\n",
    "                output_ddg_validation, labels_validation = output_model_from_batch(batch, model, device, hydra=False, train=False,)#inizio = 'wild',fine='mut')\n",
    "                output_ddg_HYDRA_SLIM_validation, _ = output_model_from_batch(batch, model, device, hydra=True, train=False)      \n",
    "\n",
    "                all_preds_validation.extend(output_ddg_validation.cpu().reshape(-1).tolist())\n",
    "                all_labels_validation.extend(labels_validation.cpu().tolist()) #MESSO UN -  se DEF AL CONTRARIO\n",
    "\n",
    "                all_preds_validation_TRANS.extend(output_ddg_HYDRA_SLIM_validation.cpu().reshape(-1).tolist())\n",
    "\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            val_loss = mean_squared_error(all_preds_validation, all_labels_validation)\n",
    "            loss_ddg_validation.append(val_loss)\n",
    "\n",
    "            val_loss_TRANS = mean_squared_error(all_preds_validation_TRANS, all_preds_validation)\n",
    "            loss_ddg_validation_TRANS.append(val_loss_TRANS)\n",
    "\n",
    "            loss_ddg_validation_TOT.append(val_loss+val_loss_TRANS)\n",
    "            \n",
    "            \n",
    "            val_correlation, _ = pearsonr(all_preds_validation, all_labels_validation)\n",
    "            pearson_r_validation.append(val_correlation)\n",
    "\n",
    "        # print(f'pearson tra triangolazione e non triangolazione : {test_correlation_TRANS}\\n')\n",
    "        # print(f'pearson tra triangolazione e true ddg: {pearsonr(all_preds_test_TRANS, all_labels_test)}\\n')\n",
    "        \n",
    "        if val_correlation >= max(pearson_r_validation): \n",
    "            best_model = copy.deepcopy(model)\n",
    "            print(f'\\033[91mEpoch {epoch+1}/{num_epochs}')\n",
    "            print(f'Train -  trans_loss={train_loss_TRANS:.4f},    Loss: {train_loss:.4f}, Pearson r: {train_correlation:.4f}, Rho spearman: {train_spearman:.4f}')\n",
    "            print(f'Validation - Loss: {val_loss:.4f}, Pearson r: {val_correlation:.4f}, Rho spearman: {spearmanr(all_preds_validation, all_labels_validation)[0]:.4f}',)        \n",
    "            print(f'Test - trans_loss={test_loss_TRANS:.4f},      Loss: {test_loss:.4f}, Pearson r: {test_correlation:.4f}, Rho spearman: {spearmanr(all_preds_test, all_labels_test)[0]:.4f}\\033[0m\\n')\n",
    "      \n",
    "\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print(f'Train -    trans_loss={train_loss_TRANS:.4f},    Loss: {train_loss:.4f}, Pearson r: {train_correlation:.4f}, Rho spearman: {train_spearman:.4f}')\n",
    "            print(f'Validation - Loss: {val_loss:.4f}, Pearson r: {val_correlation:.4f}, Rho spearman: {spearmanr(all_preds_validation, all_labels_validation)[0]:.4f}',)        \n",
    "            print(f'Test -  trans_loss={test_loss_TRANS:.4f}      Loss: {test_loss:.4f}, Pearson r: {test_correlation:.4f}, Rho spearman: {spearmanr(all_preds_test, all_labels_test)[0]:.4f}\\n')\n",
    "                  \n",
    "        if epoch > (np.argmax(pearson_r_validation) + patience):\n",
    "            print(f'\\033[91mEarly stopping at epoch {epoch+1}\\033[0m')\n",
    "            break\n",
    "    \n",
    "    pearson_max_val = np.max(pearson_r_validation)\n",
    "\n",
    "    return pearson_r_train, pearson_r_validation, pearson_r_test, loss_ddg_train, loss_ddg_validation, loss_ddg_test, loss_ddg_train_TRANS, loss_ddg_validation_TRANS, loss_ddg_test_TRANS, loss_ddg_train_TOT, loss_ddg_validation_TOT, loss_ddg_test_TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f7e6d-973d-4fb4-bf11-e89af78108e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Cross_Attention_DDG(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_module, cross_att=False, dual_cross_att= False, hydra=True ,**transf_parameters):\n",
    "        super().__init__()\n",
    "        self.base_ddg = base_module(**transf_parameters, cross_att=cross_att, dual_cross_att= dual_cross_att).to(device)\n",
    "        self.hydra=hydra\n",
    "    \n",
    "    def forward(self, x_wild, x_mut, hydra_slim, length, hydra=False, train = True):\n",
    "\n",
    "        if train:\n",
    "            if hydra:\n",
    "                \n",
    "                # Calcolo DDG tra wild e primo intermezzo\n",
    "                delta_dir = x_wild - hydra_slim\n",
    "                wild_half_DDG = self.base_ddg(delta_dir, x_wild, length)\n",
    "                \n",
    "                # Calcolo DDG tra ultimo intermezzo e mutato\n",
    "                delta_dir = hydra_slim - x_mut\n",
    "                half_mut_DDG = self.base_ddg(delta_dir, hydra_slim, length)\n",
    "                \n",
    "                # Somma totale\n",
    "                output_TCA = wild_half_DDG + half_mut_DDG\n",
    "    \n",
    "            else:\n",
    "                # Calcolo DDG tra wild e primo intermezzo\n",
    "                delta_dir = x_wild - x_mut\n",
    "                output_TCA = self.base_ddg(delta_dir, x_wild, length)         \n",
    "    \n",
    "        else:\n",
    "            if hydra:\n",
    "                \n",
    "                # Calcolo DDG tra wild e primo intermezzo\n",
    "                delta_dir = x_wild - hydra_slim\n",
    "                delta_inv = hydra_slim - x_wild\n",
    "                wild_half_DDG = (self.base_ddg(delta_dir, x_wild, length) - self.base_ddg(delta_inv, hydra_slim, length)) / 2\n",
    "                \n",
    "                # Calcolo DDG tra ultimo intermezzo e mutato\n",
    "                delta_dir = hydra_slim - x_mut\n",
    "                delta_inv = x_mut - hydra_slim\n",
    "                half_mut_DDG = (self.base_ddg(delta_dir, hydra_slim, length) - self.base_ddg(delta_inv, x_mut, length)) / 2\n",
    "                \n",
    "                # Somma totale\n",
    "                output_TCA = wild_half_DDG + half_mut_DDG\n",
    "    \n",
    "            else:\n",
    "                # Calcolo DDG tra wild e primo intermezzo\n",
    "                delta_dir = x_wild - x_mut\n",
    "                delta_inv = x_mut - x_wild\n",
    "                output_TCA = (self.base_ddg(delta_dir, x_wild, length) - self.base_ddg(delta_inv, x_mut, length)) / 2            \n",
    "            \n",
    "        return output_TCA  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98febd2-26c0-4c75-9768-9a9871b263e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_masked_pooling(position_attn_output, padding_mask):\n",
    "\n",
    "    # Convert mask to float for element-wise multiplication\n",
    "    padding_mask = padding_mask.float()\n",
    "\n",
    "    # Global Average Pooling (GAP) - Exclude padded tokens\n",
    "    # Sum only over valid positions (padding_mask is False for valid positions)\n",
    "    sum_output = torch.sum(position_attn_output * (1 - padding_mask.unsqueeze(-1)), dim=1)  # (batch_size, feature_dim)\n",
    "    valid_count = torch.sum((1 - padding_mask).float(), dim=1)  # (batch_size,)\n",
    "    gap = sum_output / valid_count.unsqueeze(-1)  # Divide by number of valid positions\n",
    "\n",
    "    # Global Max Pooling (GMP) - Exclude padded tokens\n",
    "    # Set padded positions to -inf so they don't affect the max computation\n",
    "    position_attn_output_masked = position_attn_output * (1 - padding_mask.unsqueeze(-1)) + (padding_mask.unsqueeze(-1) * (- 1e10))\n",
    "    gmp, _ = torch.max(position_attn_output_masked, dim=1)  # (batch_size, feature_dim)\n",
    "\n",
    "    return gap, gmp\n",
    "\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=3700):\n",
    "        super(SinusoidalPositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape (1, max_len, embedding_dim)\n",
    "        self.register_buffer('pe', pe)  # Salvato come tensore fisso (non parametro)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_heads=8, dropout_rate=0., num_experts=1, f_activation = nn.ReLU(), kernel_size=20, cross_att = True,\n",
    "                dual_cross_att=True):\n",
    "        \n",
    "        super(TransformerRegression, self).__init__()\n",
    "\n",
    "        self.embedding_dim = input_dim\n",
    "        self.act = f_activation\n",
    "        self.max_len = 3700 #lunghezza massima proteina\n",
    "        out_channels = 128  #num filtri conv 1D\n",
    "        kernel_size = 20\n",
    "        padding = 0\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding) \n",
    "        \n",
    "        self.conv1d_wild = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(out_channels)\n",
    "        self.norm2 = nn.LayerNorm(out_channels)\n",
    "        \n",
    "        # Cross-attention layers\n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(out_channels, 3700)\n",
    "        self.speach_att_type = True\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first=True )\n",
    "        self.inverse_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first =True)\n",
    "        \n",
    "        dim_position_wise_FFN = out_channels*2\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(dim_position_wise_FFN)\n",
    "        self.router = nn.Linear(dim_position_wise_FFN, num_experts) #dim_position_wise_FFN*2\n",
    "\n",
    "        self.pw_ffnn = nn.Sequential(\n",
    "            nn.Linear(dim_position_wise_FFN, 512),\n",
    "            self.act,\n",
    "            nn.Linear(512, dim_position_wise_FFN)\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.Linear_ddg = nn.Linear(dim_position_wise_FFN*2, 1)\n",
    "\n",
    "            \n",
    "\n",
    "    def create_padding_mask(self, length, seq_len, batch_size):\n",
    "        \"\"\"\n",
    "        Create a padding mask for multihead attention.\n",
    "        length: Tensor of shape (batch_size,) containing the actual lengths of the sequences.\n",
    "        seq_len: The maximum sequence length.\n",
    "        batch_size: The number of sequences in the batch.\n",
    "        \n",
    "        Returns a padding mask of shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        mask = torch.arange(seq_len, device=length.device).unsqueeze(0) >= length.unsqueeze(1)\n",
    "        return mask\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, delta_w_m, x_wild, length):\n",
    "            \n",
    "            delta_w_m = delta_w_m.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_delta_w_m = self.conv1d(delta_w_m)\n",
    "            C_delta_w_m = C_delta_w_m.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_delta_w_m = self.positional_encoding(C_delta_w_m)\n",
    "            \n",
    "            x_wild = x_wild.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_x_wild = self.conv1d_wild(x_wild)\n",
    "            C_x_wild = C_x_wild.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_x_wild = self.positional_encoding(C_x_wild)            \n",
    "            \n",
    "            batch_size, seq_len, feature_dim = C_x_wild.size()\n",
    "\n",
    "            padding_mask = self.create_padding_mask(length, seq_len, batch_size)        \n",
    "                    \n",
    "            if self.speach_att_type:\n",
    "                print('ATTENTION TYPE: Dual cross Attention\\n q = wild , k = delta, v = delta and q = delta , k = wild, v = wild \\n ----------------------------------')\n",
    "                self.speach_att_type = False\n",
    "                \n",
    "            direct_attn_output, _ = self.multihead_attention(C_x_wild, C_delta_w_m, C_delta_w_m, key_padding_mask=padding_mask)\n",
    "            direct_attn_output += C_delta_w_m \n",
    "            direct_attn_output = self.norm1(direct_attn_output)                        \n",
    "            \n",
    "            inverse_attn_output, _ = self.inverse_attention(C_delta_w_m, C_x_wild, C_x_wild, key_padding_mask=padding_mask)                   \n",
    "            inverse_attn_output += C_x_wild  \n",
    "            inverse_attn_output = self.norm2(inverse_attn_output)\n",
    "            \n",
    "            attn_output = torch.cat([direct_attn_output, inverse_attn_output], dim=-1)\n",
    "\n",
    "            output = self.pw_ffnn(attn_output)\n",
    "    \n",
    "            position_attn_output = attn_output + output\n",
    "    \n",
    "            position_attn_output = self.norm3(position_attn_output)\n",
    "    \n",
    "            gap, gmp = apply_masked_pooling(position_attn_output, padding_mask)\n",
    "    \n",
    "            # Concatenate GAP and GMP\n",
    "            pooled_output = torch.cat([gap, gmp], dim=-1)  # (batch_size, 2 * feature_dim)\n",
    "    \n",
    "            # Pass through FFNN to predict DDG\n",
    "            x = self.Linear_ddg(pooled_output)        \n",
    "            \n",
    "            return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e28f9-35f3-49c6-b2f6-6e53c433b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245621e5-bf63-4d4f-a923-f1bac00c67ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "input_dim = 1280\n",
    "transf_parameters={'input_dim':1280, 'num_heads':8,\n",
    "                    'dropout_rate':0.,}\n",
    "\n",
    "patience = 300\n",
    "DDG_model = TransformerRegression\n",
    "Final_model =torch.load('JanusDDG.pth', map_location=torch.device('cpu'))\n",
    "path_save_fig = 'JanusDDG \\n ----------------------------------'\n",
    "print(path_save_fig)\n",
    "pearson_r_train, pearson_r_validation, pearson_r_test, loss_ddg_train, loss_ddg_validation, loss_ddg_test, loss_ddg_train_TRANS, loss_ddg_validation_TRANS, loss_ddg_test_TRANS, loss_ddg_train_TOT, loss_ddg_validation_TOT, loss_ddg_test_TOT = training_and_validation_loop_ddg(Final_model, dataloader_train, dataloader_test,\n",
    "                                                                                   dataloader_validation,\n",
    "                                                                                   path_save_fig, epochs=28, lr =lr,patience = patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e952136-63d8-44ab-acad-b5b7e3682d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(Final_model, 'JanusDDG_fine_tuned.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
